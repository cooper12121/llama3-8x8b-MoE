#  Llama3-8Ã—8b-MoE 
  
[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](./README.md) | [**ğŸŒEnglish**](./README_EN.md) 

<p align="center">
    <br>
    <img src="./figures/llama3-MoE.jpg" width="800"/>
    <br>
</p>
<!-- <p align="center">
    <img alt="GitHub" src="https://img.shields.io/github/license/cooper12121/Llama3-8Ã—8b-MoE .svg?color=blue&style=flat-square">
    <img alt="GitHub release (latest by date)" src="https://img.shields.io/github/v/release/cooper12121/llama3-Chinese">
    <img alt="GitHub top language" src="https://img.shields.io/github/languages/top/cooper12121/llama3-Chinese">
    <a href="https://app.codacy.com/gh/cooper12121/llama3-Chinese/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade"><img src="https://app.codacy.com/project/badge/Grade/142d688425494644b5b156068f55370d"/></a>
</p> -->

æœ¬é¡¹ç›®åŸºäºMetaå‘å¸ƒçš„[llama3-8B-Instructæ¨¡å‹](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Chat)è¿›è¡Œå¼€å‘ã€‚å³å°†MLPå¤åˆ¶8ä»½ï¼Œåˆ›å»ºä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„routerï¼Œå…¶ä½™å‚æ•°æƒé‡ä¿æŒä¸å˜ï¼Œæ­å»ºä¸€ä¸ªçƒ­å¯åŠ¨çš„MoEæ¨¡å‹ã€‚è¿™ç§æ–¹å¼èƒ½å¤Ÿæå¤§åœ°é™ä½ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªMoEæ¨¡å‹çš„æˆæœ¬ï¼Œä¾¿äºå¿«é€Ÿçš„åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å¾®è°ƒä½¿ç”¨ã€‚



#### æœ¬é¡¹ç›®ä¸»è¦å†…å®¹

- ğŸš€ å¼€æºllama3-8Ã—8b-MoE-Base/InstructåŸºæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨[llama3-8B-Base/Instructæ¨¡å‹](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)çš„åŸºç¡€ä¸Šæ‰©å±•ä¸ºMoEæ¶æ„ã€‚
- ğŸš€ æä¾›routeréšæœºåˆå§‹åŒ–å’Œä½¿ç”¨chinese-mixtral [ymcui/Chinese-Mixtral](https://github.com/ymcui/Chinese-Mixtral)çš„routeræƒé‡è¿›è¡Œåˆå§‹åŒ–çš„ä¸¤ä¸ªç‰ˆæœ¬çš„æƒé‡
- ğŸš€ å¼€æºæ‰©å±•è„šæœ¬ã€æƒé‡è½¬æ¢è„šæœ¬ã€‚
- ğŸš€ é’ˆå¯¹æ­å»ºçš„MoEæ¨¡å‹è¿›è¡Œé€šç”¨sftæ•°æ®å¾®è°ƒï¼Œä¸ç°æœ‰çš„MoEæ¨¡å‹è¿›è¡Œæ¯”è¾ƒ

----



## æ–°é—»
**ğŸš€ğŸš€ğŸš€ğŸš€ æŒç»­æ›´æ–°ä¸­ï¼Œè¯·ç­‰å¾…** 

**[2024/05/04] ğŸš€ å¼€æºæƒé‡è½¬æ¢è„šæœ¬ï¼Œä¸Šä¼ ```Llama3-8Ã—8b-MoE-Instruct/Base``` ç‰ˆæœ¬å’Œ```Llama3-8Ã—8b-MoE-Instruct/Base-router_warmboot```ç‰ˆæœ¬ï¼Œæ¬¢è¿å¤§å®¶ä½¿ç”¨ï¼Œä¹Ÿå¸Œæœ›å¤§å®¶èƒ½åœ¨æœ¬ä»“åº“åé¦ˆè¯¥MoEæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ•ˆæœ** 

**[2024/05/01] ğŸš€ å¼€æºllama3-8Ã—8b-MoEæ¨¡å‹ä»£ç ï¼Œè§modeling_file/modeling_llama_MoE.py, è¯¥ä»£ç å¯¹llama-1/2/3å‡é€‚ç”¨ã€‚** 

**[2024/04/28] ğŸš€ åˆ›å»ºä»“åº“ï¼Œä¸Šä¼ READMEæ–‡æ¡£**


## å†…å®¹å¯¼å¼•
| ç« èŠ‚                                  | æè¿°                                                         |
| ------------------------------------- | ------------------------------------------------------------|
| [ğŸ° æ‰©å±•MoEæ¶æ„åŠè®­ç»ƒç»éªŒè®°å½•](#1-æ‰©å±•moeæ¶æ„åŠè®­ç»ƒç»éªŒè®°å½•) |ä½œè€…ä¹‹å‰è‡ªå»ºYi-8x6b/4x4b MoEå’Œæœ¬é¡¹ç›®llama3-8x8b MoEçš„ç»éªŒä½“ä¼š|
| [â¬æ¨¡å‹ä¸‹è½½](#æ¨¡å‹ä¸‹è½½)        | Llama3-8Ã—8b-MoEå¤§æ¨¡å‹ä¸‹è½½åœ°å€    |
| [ğŸ’¯æ¨¡å‹æ•ˆæœ](#æ¨¡å‹æ•ˆæœ) | ä»‹ç»äº†æ¨¡å‹åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šçš„æ•ˆæœ    |
| [ğŸ“è®­ç»ƒä¸ç²¾è°ƒ](#è®­ç»ƒä¸ç²¾è°ƒ) | ä»‹ç»äº†ç²¾è°ƒllama3-8Ã—8b-MoEå¤§æ¨¡å‹ |
| [â“å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜) | ä¸€äº›å¸¸è§é—®é¢˜çš„å›å¤ |

## 1. æ‰©å±•MoEæ¶æ„åŠè®­ç»ƒç»éªŒè®°å½•
**1.1 çƒ­å¯åŠ¨MoE Baseç‰ˆæœ¬ä¸Instructç‰ˆæœ¬çš„åŒºåˆ«**

**1.2 routeréšæœºåˆå§‹åŒ–åBaseç‰ˆæœ¬å’ŒInstructç‰ˆæœ¬routerçš„è®­ç»ƒç¨³å®šæ€§é—®é¢˜**

**1.3 ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„routerå¦‚mixtral-8x7b-MoE, è¿›è¡Œrouterçš„çƒ­å¯åŠ¨èƒ½å¦æå‡è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½**

**1.4 Baseå’ŒInstruct MoEæ¨¡å‹routerå¯¹tokençš„åˆ†é…ç­–ç•¥é—®é¢˜**

## 2. æ¨¡å‹ä¸‹è½½
**ç‰ˆæœ¬è§£é‡Š**
> 1. routeréšæœºåˆå§‹åŒ–ï¼šhugginging faceInstruct/Baseåç¼€

> 2. router ä½¿ç”¨chinese-mixtral-base/Instructçš„routeræƒé‡åˆå§‹åŒ–ï¼šrouter_warmbootåç¼€
### ä¸‹è½½åœ°å€

| æ¨¡å‹åç§°                  |   ç±»å‹   |                    è§„æ ¼                    |                    å®Œæ•´ç‰ˆ GBï¼‰                    |
| :------------------------ | :------: | :----------------------------------------------------------: | :----------------------------------------------------------: | 
| Llama3-8x8b-MoE-Base | åŸºåº§æ¨¡å‹ | 8x8B | [[ğŸ¤—HF]](https://huggingface.co/gao-NLP/Llama3-8x8b-MoE-Base) |
| Llama3-8x8b-MoE-Instruct | æŒ‡ä»¤æ¨¡å‹ | 8x8B |[[ğŸ¤—HF]](https://huggingface.co/gao-NLP/Llama3-8x8b-MoE-Instruct) | 

### æ¨¡å‹é€‰æ‹©æŒ‡å¼•

ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®çš„æ¨¡å‹å¯¹æ¯”ä»¥åŠå»ºè®®ä½¿ç”¨åœºæ™¯ã€‚**å¦‚éœ€èŠå¤©äº¤äº’ï¼Œè¯·é€‰æ‹©Instructç‰ˆã€‚**

| å¯¹æ¯”é¡¹                |  Llama3-8Ã—8b-MoE-Instruct                                     | Llama3-8B-Instruct                                 |  Mixtral-8Ã—7B-MoE-Instruct | Deepseek-MoE-Chat| Qwen1.5-MoE-chat |
| :-------------------- | :----------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------:  |  :----------------------------------------------------------: | :----------------------------------------------------------:  |
| æ¨¡å‹ç±»å‹ | **åŸºåº§æ¨¡å‹** | **æŒ‡ä»¤/Chatæ¨¡å‹ï¼ˆç±»ChatGPTï¼‰** |
| æ¨¡å‹å¤§å° |    8Ã—8B                          |            8B |
| è®­ç»ƒç±»å‹     | Causal-LM (CLM)           | æŒ‡ä»¤ç²¾è°ƒ                                                     |
| è®­ç»ƒæ–¹å¼ | å…¨å‚æ•°                         | å…¨å‚æ•° |
| åŸºäºä»€ä¹ˆæ¨¡å‹è®­ç»ƒ | meta/Llama3-8B-Instruct |  |
| è®­ç»ƒè¯­æ–™ | |   |
| è¯è¡¨å¤§å° | åŸç‰ˆè¯è¡¨ï¼Œ127999 | åŸç‰ˆè¯è¡¨ï¼Œ 127999 |


## 3. æ¨¡å‹æ•ˆæœ

ä¸ºäº†è¯„æµ‹ç›¸å…³æ¨¡å‹çš„æ•ˆæœï¼Œæœ¬é¡¹ç›®åˆ†åˆ«è¿›è¡Œäº†ç”Ÿæˆæ•ˆæœè¯„æµ‹å’Œå®¢è§‚æ•ˆæœè¯„æµ‹ï¼ˆNLUç±»ï¼‰ï¼Œä»ä¸åŒè§’åº¦å¯¹å¤§æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚æ¨èç”¨æˆ·åœ¨è‡ªå·±å…³æ³¨çš„ä»»åŠ¡ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œé€‰æ‹©é€‚é…ç›¸å…³ä»»åŠ¡çš„æ¨¡å‹ã€‚


### å®¢è§‚æ•ˆæœè¯„æµ‹

#### C-Eval

[C-Eval](https://cevalbenchmark.com)æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„ä¼°å¥—ä»¶ï¼Œå…¶ä¸­éªŒè¯é›†å’Œæµ‹è¯•é›†åˆ†åˆ«åŒ…å«1.3Kå’Œ12.3Kä¸ªé€‰æ‹©é¢˜ï¼Œæ¶µç›–52ä¸ªå­¦ç§‘ã€‚

| Models             | ç±»å‹ | Valid (0-shot) | Valid (5-shot) | Test (0-shot) | Test (5-shot) |
| ------------------------ | :------------: | :------------: | :-----------: | :-----------: | :-----------: |
| **Llama3-8Ã—8b-MoE-Instruct** |  | |  |  |  |
| **Llama3-8B-Instruct**  |  |  |  | |  |
| **Mixtral-8Ã—7B-MoE-Instruct**  |  |  |  | |  |
| **Deepseek-MoE-Chat**  |  |  |  | |  |
| **Qwen1.5-MoE-chat**  |  |  |  | |  |



#### CMMLU



#### MMLU



#### LongBench


### é‡åŒ–æ•ˆæœè¯„æµ‹



## 4. è®­ç»ƒä¸ç²¾è°ƒ

### é¢„è®­ç»ƒ


### æŒ‡ä»¤ç²¾è°ƒ





## 5. å¸¸è§é—®é¢˜
**1. triu_tril_cuda_template" not implemented for 'BFloat16**

  è¿™æ˜¯torchç‰ˆæœ¬çš„é—®é¢˜ï¼Œåœ¨torch 2.1.0ä¹‹åçš„ç‰ˆæœ¬å·²ç»ä¿®å¤
ï¼Œå¯¹äºtorch 2.1.0ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œç›®å‰æœ‰ä¸‰ç§è§£å†³æ–¹æ¡ˆ
* æ–¹æ³•1ï¼šåœ¨modeling_llama.py line 1095  
  å°†```causal_mask = torch.triu(causal_mask, diagonal=1)```  
  ä¿®æ”¹ä¸ºï¼š
  ```
  causal_mask = causal_mask.to(torch.float32)#
  causal_mask = torch.triu(causal_mask, diagonal=1)
  causal_mask = causal_mask.to('cuda', dtype=torch.bfloat16)#
  ```
* æ–¹æ³•2ï¼šåœ¨modeling_llama.py line 1094è¡Œå‰æ·»åŠ ï¼š  
  ```self.register_buffer("triu0",torch.ones(sequence_length, target_length).to("cuda").triu())```  
  å°†line 1095 ```causal_mask = torch.triu(causal_mask, diagonal=1)```  
  ä¿®æ”¹ä¸ºï¼š```causal_mask=causal_mask*self.triu0```
* æ–¹æ³•3ï¼šåœ¨åŠ è½½æ¨¡å‹å‰çš„ä»£ç ä¸­æ·»åŠ 
  ```torch.set_default_tensor_type(torch.cuda.HalfTensor)```
  ä½†è¿™ç§æ–¹å¼å¯èƒ½å¼•èµ·cudaå†…æ ¸çš„pin_memoryé”™è¯¯ï¼Œå¯è¡Œä¸å¦ä¸å…·ä½“çš„ç¯å¢ƒæœ‰å…³





